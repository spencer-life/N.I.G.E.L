/**
 * LlamaIndex Integration for NIGEL
 * 
 * Provides LlamaIndex-compatible vector index wrapper around Supabase
 * Enables advanced document processing, chunking strategies, and query engines
 * 
 * Usage:
 * ```typescript
 * import { SupabaseVectorIndex } from './integrations/llamaindex/SupabaseVectorIndex';
 * 
 * const index = new SupabaseVectorIndex();
 * 
 * // Ingest documents with automatic chunking
 * await index.ingestDocuments([
 *   { text: '...', metadata: { framework: 'FATE' } }
 * ]);
 * 
 * // Query with advanced retrieval
 * const response = await index.query('What is elicitation?');
 * ```
 */

import { supabase } from "../../database/client.js";
import type { Chunk } from "../../types/database.js";

export interface LlamaDocument {
  text: string;
  metadata?: {
    framework?: string;
    section?: string;
    documentName?: string;
    [key: string]: any;
  };
}

export interface QueryOptions {
  topK?: number;
  similarityThreshold?: number;
  frameworkFilter?: string[];
  useHybrid?: boolean;
}

export interface QueryResponse {
  response: string;
  sourceNodes: Array<{
    text: string;
    score: number;
    metadata: Record<string, any>;
  }>;
}

/**
 * Supabase Vector Index for LlamaIndex
 * Wraps NIGEL's vector search with LlamaIndex-style interface
 */
export class SupabaseVectorIndex {
  /**
   * Ingest documents into the vector store
   * Handles automatic chunking and embedding generation via database triggers
   */
  async ingestDocuments(documents: LlamaDocument[]): Promise<void> {
    for (const doc of documents) {
      const documentName = doc.metadata?.documentName || 'Untitled';
      const framework = doc.metadata?.framework || 'general';
      const section = doc.metadata?.section || null;

      // Create or get document
      const { data: existingDoc } = await supabase
        .from('documents')
        .select('id')
        .eq('name', documentName)
        .single();

      let documentId: number;

      if (!existingDoc) {
        const { data: newDoc, error } = await supabase
          .from('documents')
          .insert({
            name: documentName,
            source: doc.metadata?.source || null,
            doc_type: 'markdown',
            metadata: doc.metadata || {}
          })
          .select('id')
          .single();

        if (error) throw new Error(`Failed to create document: ${error.message}`);
        documentId = newDoc.id;
      } else {
        documentId = existingDoc.id;
      }

      // Chunk the document (simple sentence-based chunking)
      // In production, you'd use more sophisticated chunking strategies
      const chunks = this.chunkText(doc.text, 400, 50);

      // Insert chunks (embeddings generated automatically)
      for (const chunkText of chunks) {
        const { error: chunkError } = await supabase
          .from('chunks')
          .insert({
            document_id: documentId,
            section,
            content: chunkText,
            framework_tags: [framework],
            token_count: chunkText.split(/\s+/).length,
            // embedding will be generated by trigger
          });

        if (chunkError) {
          console.error(`Failed to insert chunk: ${chunkError.message}`);
        }
      }
    }
  }

  /**
   * Query the index with advanced retrieval
   */
  async query(
    queryText: string,
    options: QueryOptions = {}
  ): Promise<QueryResponse> {
    const {
      topK = 5,
      similarityThreshold = 0.5,
      frameworkFilter = null,
      useHybrid = false
    } = options;

    let results: any[];

    if (useHybrid) {
      // Use hybrid search
      const { data, error } = await supabase.rpc("hybrid_search_chunks", {
        query_text: queryText,
        query_embedding: [], // Would generate embedding here
        match_count: topK,
        full_text_weight: 1.0,
        semantic_weight: 1.0,
        rrf_k: 50
      });

      if (error) throw new Error(`Hybrid search failed: ${error.message}`);
      results = data || [];
    } else {
      // Use vector search
      const { data, error } = await supabase.rpc("search_chunks_optimized", {
        query_embedding: [], // Would generate embedding here
        match_threshold: 2 * (1 - similarityThreshold),
        match_count: topK,
        framework_filter: frameworkFilter,
        boost_section_match: null
      });

      if (error) throw new Error(`Vector search failed: ${error.message}`);
      results = data || [];
    }

    // Format as LlamaIndex-style response
    const sourceNodes = results.map((chunk: any) => ({
      text: chunk.content,
      score: chunk.similarity || (1 - chunk.distance / 2),
      metadata: {
        id: chunk.id,
        section: chunk.section,
        framework_tags: chunk.framework_tags,
        document_id: chunk.document_id
      }
    }));

    // Synthesize response (placeholder - would use Claude here)
    const response = this.synthesizeResponse(queryText, sourceNodes);

    return {
      response,
      sourceNodes
    };
  }

  /**
   * Simple text chunking strategy
   * In production, use more sophisticated methods (semantic chunking, etc.)
   */
  private chunkText(text: string, targetSize: number, overlap: number): string[] {
    const sentences = text.match(/[^.!?]+[.!?]+/g) || [text];
    const chunks: string[] = [];
    let currentChunk: string[] = [];
    let currentSize = 0;

    for (const sentence of sentences) {
      const sentenceSize = sentence.split(/\s+/).length;

      if (currentSize + sentenceSize > targetSize && currentChunk.length > 0) {
        chunks.push(currentChunk.join(' '));
        // Keep last few sentences for overlap
        const overlapSentences = Math.floor(overlap / (currentSize / currentChunk.length));
        currentChunk = currentChunk.slice(-overlapSentences);
        currentSize = currentChunk.reduce((sum, s) => sum + s.split(/\s+/).length, 0);
      }

      currentChunk.push(sentence);
      currentSize += sentenceSize;
    }

    if (currentChunk.length > 0) {
      chunks.push(currentChunk.join(' '));
    }

    return chunks;
  }

  /**
   * Synthesize response from retrieved chunks
   * Placeholder - would integrate with Claude API
   */
  private synthesizeResponse(query: string, sourceNodes: any[]): string {
    if (sourceNodes.length === 0) {
      return "No relevant information found in the knowledge base.";
    }

    // In production, this would call Claude with the context
    return `Based on ${sourceNodes.length} relevant sources, here's what I found about "${query}"...`;
  }

  /**
   * Get index statistics
   */
  async getStats(): Promise<{
    totalChunks: number;
    totalDocuments: number;
    frameworks: string[];
  }> {
    const { count: chunkCount } = await supabase
      .from('chunks')
      .select('*', { count: 'exact', head: true });

    const { count: docCount } = await supabase
      .from('documents')
      .select('*', { count: 'exact', head: true });

    const { data: frameworkData } = await supabase
      .from('chunks')
      .select('framework_tags');

    const frameworks = new Set<string>();
    frameworkData?.forEach(row => {
      row.framework_tags.forEach((tag: string) => frameworks.add(tag));
    });

    return {
      totalChunks: chunkCount || 0,
      totalDocuments: docCount || 0,
      frameworks: Array.from(frameworks)
    };
  }
}

/**
 * Example usage patterns
 */
export const examples = {
  // Ingest new documents
  ingestDocuments: async () => {
    const index = new SupabaseVectorIndex();
    await index.ingestDocuments([
      {
        text: "FATE stands for Focus, Authority, Tribe, and Emotion...",
        metadata: {
          framework: "FATE",
          section: "Overview",
          documentName: "FATE Framework Guide"
        }
      }
    ]);
  },

  // Basic query
  basicQuery: async () => {
    const index = new SupabaseVectorIndex();
    const response = await index.query("What is FATE?", { topK: 5 });
    return response;
  },

  // Filtered query
  filteredQuery: async () => {
    const index = new SupabaseVectorIndex();
    const response = await index.query(
      "How do I build rapport?",
      {
        topK: 5,
        frameworkFilter: ['rapport', 'human needs']
      }
    );
    return response;
  },

  // Hybrid search query
  hybridQuery: async () => {
    const index = new SupabaseVectorIndex();
    const response = await index.query(
      "elicitation techniques",
      {
        topK: 5,
        useHybrid: true
      }
    );
    return response;
  },

  // Get statistics
  getStats: async () => {
    const index = new SupabaseVectorIndex();
    const stats = await index.getStats();
    console.log(`Total chunks: ${stats.totalChunks}`);
    console.log(`Total documents: ${stats.totalDocuments}`);
    console.log(`Frameworks: ${stats.frameworks.join(', ')}`);
    return stats;
  }
};
